---
title: "Prognosticator Functions"
author: "Justin Papreck"
date: "January 25, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pipeline
1. Read finalized ngram probability file
2. Read input phrase and count the maximum number of words in string
3. Determine if any of the words in the input string have unknown words
4. Process the input string, look for anything starting with 6-grams
5. Run the Stupid Backoff
6. Final Prognosticate Model is defined with previous nested functions

## 1. Read finalized ngram probability file
    Open the file that has the n-grams and the associated probabilities. The phrase is the n - 1 gram, since the prediction term is subtracted. The associated probability is then calculated with the associated predictive terms. 
```{r read, echo=TRUE}
    nGrams <- fread(paste0(path, "filtered.txt"), col.names = c("phrase", "prediction", "probability"), data.table = T, stringsAsFactors = F, encoding = "UTF-8")
    lambda <- 0.4
    setkey(nGrams, phrase)
```

## 2. Read input phrase and count the maximum number of words in string
    Determine whether the input string exists within the file 'filtered.txt' with a subsequent probable prediction
```{r tokenize, echo=TRUE}
    nTokens <- function(input.Phrase) {
        if (input.Phrase == "") return(0)
        return(str_count(input.Phrase, "_") + 1)
    }
```

## 3. Determine if any of the words in the input string have unknown words
    This cuts off the first word in the input string. If the string is only of length 1, then it returns an 'NA'
```{r ngram, echo=TRUE}
    nGram.Axe <- function(input.Phrase) {
        if (nTokens(input.Phrase) == 1) return("<NA>")
        return(sub("^[^_]*_", "", input.Phrase))
    }
```

## 4. Process the input string, look for anything starting with 6-grams
    The input.Axe function tokenizes the input string, then takes the highest number of words in the string and determines whether the string is starting up to a 6 gram. Since there is nothing greater than a 5-gram, and in the phrase, nothing greater than a 4-gram, this is more than ample. The 'else' condition lowers the number incrementally until there is an n-gram found. 
```{r input, echo=TRUE}
    input.Axe <- function(input.String, n = 6) {
        if (trimws(input.String, "both") == "") return ("<NA>")
        chops <- tokens(input.String, what = "word", remove_numbers = T, remove_punct = T, remove_symbols = T, remove_twitter = T, remove_hyphens = T, remove_url = T, remove_separators = T, ngrams = n) %>% 
            tokens_tolower() %>%
            unlist(use.names = F) %>%
            as.data.table()
        if (chops[, .N] > 0) return(chops[.N])
        else return(input.Axe(input.String, n - 1))
    }
```

## 5. Run the Stupid Backoff
    The Stupid Backoff looks at the tokenized input string and scans the ngram table for matching strings. If a result is returned, the model returns the index matching results and scales the probability based on the variable 'a'. Unless needed to reduce file size, the variable 'a' is set to 1. If no result is returned to the Axe, the ngram reduces the ngram by 1. This is based off of the Stupid Backoff Model as defined by the authors. 
```{r stupid, echo=TRUE}
    Backoff <- function(input.Phrase, a = 1) {
        result <- nGrams[phrase == input.Phrase]
        if (nrow(result) > 0) return(mutate(result, probability = a * probability))
        else return(Backoff(nGram.Axe(input.Phrase), a * lambda))
    }
```

## 6. Final Prognosticate Model is defined with previous nested functions
    The Prognosticate.R function is the actual predictor function for the front end of the application. The string is entered as an input, and then tokenized as a decreasing series of ngrams. After the tokeinzation, the ngram is passed to the Backoff function, which searches for matches and then is incrementally backed off and returnd the predictions based off the highest order ngram. 
```{r prognosticate, echo=TRUE}
    Prognosticate <- function(input.String) {
        nGram <- input.Axe(input.String)
        prognostication <- Backoff(nGram)
        return(prognostication)
    }
```
